{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [-f LR_FIND]\n",
      "ipykernel_launcher.py: error: argument -f/--lr-find: invalid int value: '/home/ameer/.local/share/jupyter/runtime/kernel-7fe750c7-5034-4614-8f6e-768680487bc6.json'\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ameer/anaconda3/envs/tf_gpu/lib/python3.7/site-packages/IPython/core/interactiveshell.py:3334: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.layers import Dropout, Flatten, Dense, Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from utils.learningratefinder import LearningRateFinder\n",
    "from utils.clr_callback import CyclicLR\n",
    "from utils import config\n",
    "from imutils import paths\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "import pickle\n",
    "import cv2\n",
    "import sys\n",
    "import os\n",
    "# argparsing\n",
    "ap = argparse.ArgumentParser()\n",
    "ap.add_argument(\"-f\", \"--lr-find\", type=int, default=0,\n",
    "\thelp=\"whether or not to find optimal learning rate\")\n",
    "args = vars(ap.parse_args())\n",
    "\n",
    "print(\"[INFO] loading images...\")\n",
    "imagePaths = list(paths.list_images(config.DATASET_PATH))\n",
    "data = []\n",
    "labels = []\n",
    "# get data and convert to arrays and onehot\n",
    "for imagePath in imagePaths:\n",
    "\tlabel = imagePath.split(os.path.sep)[-2]\n",
    "\timage = cv2.imread(imagePath)\n",
    "\timage = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\timage = cv2.resize(image, (224, 224))\n",
    "\n",
    "\tdata.append(image)\n",
    "\tlabels.append(label)\n",
    "\n",
    "print(\"[INFO] processing data...\")\n",
    "data = np.array(data, dtype=\"float32\")\n",
    "labels = np.array(labels)\n",
    "# Onehot\n",
    "lb = LabelBinarizer()\n",
    "labels = lb.fit_transform(labels)\n",
    "print(\"debug0.4\")\n",
    "# Train Test Val split\n",
    "(trainX, testX, trainY, testY) = train_test_split(data, labels, \n",
    "\ttest_size=config.TEST_SPLIT, random_state=42)\n",
    "print(trainX.shape, trainY.shape)\n",
    "(trainX, valX, trainY, valY) = train_test_split(trainX, trainY, \n",
    "\ttest_size=config.VAL_SPLIT, random_state=44)\n",
    "print(\"debug0.6\")\n",
    "# data augmentation\n",
    "aug = ImageDataGenerator(\n",
    "\trotation_range=30,\n",
    "\tzoom_range=0.15,\n",
    "\twidth_shift_range=0.2,\n",
    "\theight_shift_range=0.2,\n",
    "\tshear_range=0.15,\n",
    "\thorizontal_flip=True,\n",
    "\tfill_mode=\"nearest\")\n",
    "print(\"debug.07\")\n",
    "# Model\n",
    "base_model = VGG16(include_top=False, weights=\"imagenet\",\n",
    "\tinput_tensor=Input(shape=(224, 224, 3)), trainable=False)\n",
    "\n",
    "X = base_model.output\n",
    "X = Flatten(name=\"flatten\")(X)\n",
    "X = Dense(512, activation=\"relu\")(X)\n",
    "X = Dropout(0.5)(X)\n",
    "X = Dense(len(config.CLASSES), activation=\"softmax\")(X)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=X)\n",
    "\n",
    "print(\"[INFO] compiling model...\")\n",
    "opt = SGD(lr=config.MIN_LR, momentum=0.9)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=opt,\n",
    "\tmetrics=[\"accuracy\"])\n",
    "\n",
    "# Learning Rate Finder\n",
    "if args[\"lr_find\"] > 0:\n",
    "\tprint(\"[INFO] findinf learning rate...\")\n",
    "\tlrf = LearningRateFinder(model)\n",
    "\tlrf.find(\n",
    "\t\taug.flow(trainX, trainY, batch_size=config.BATCH_SIZE),\n",
    "\t\t1e-10, 1e+1,\n",
    "\t\tstepsPerEpoch=np.ceil((trainX.shape[0]/float(config.BATCH_SIZE))),\n",
    "\t\tepochs=20,\n",
    "\t\tbatchSize=config.BATCH_SIZE)\n",
    "\t\n",
    "\tlrf.plot_loss()\n",
    "\tplt.savefig(config.LRFIND_PLOT_PATH)\n",
    "\n",
    "\tprint(\"[INFO] learning rate finder complete...\")\n",
    "\tprint(\"[INFO] examine plot and adjust learning rate before training\")\n",
    "\tsys.exit(0)\n",
    "\n",
    "# Continue after adjusting Learning Rates\n",
    "stepSize = config.STEP_SIZE * (trainX.shape[0] // config.BATCH_SIZE)\n",
    "clr = CyclicLR(\n",
    "\tmode=config.CLR_METHOD,\n",
    "\tbase_lr=config.MIN_LR,\n",
    "\tmax_lr=config.MAX_LR,\n",
    "\tstep_size=stepSize\n",
    ")\n",
    "\n",
    "# train\n",
    "print(\"[INFO] training...\")\n",
    "history = model.fit_generator(\n",
    "\taug.flow(trainX, trainY, batchSize=config.BATCH_SIZE),\n",
    "\tvalidation_data=(valX, valY),\n",
    "\tsteps_per_epoch=trainX.shape[0]//config.BATCH_SIZE,\n",
    "\tepochs=config.NUM_EPOCHS,\n",
    "\tcallbacks=[clr],\n",
    "\tverbose=1)\n",
    "\n",
    "# Evaluate\n",
    "print(\"[INFO] evaluating network...\")\n",
    "predictions = model.predict(testX, batch_size=config.BATCH_SIZE)\n",
    "print(classification_report(testY.argmax(axis=1),\n",
    "\tpredictions.argmax(axis=1), target_names=config.CLASSES))\n",
    "\n",
    "print(\"[INFO] serializing network to '{}'...\".format(config.MODEL_PATH))\n",
    "model.save(config.MODEL_PATH)\n",
    "\n",
    "# plot\n",
    "\n",
    "N = np.arange(0, config.NUM_EPOCHS)\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(N, history.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(N, history.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(N, history.history[\"accuracy\"], label=\"train_acc\")\n",
    "plt.plot(N, history.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.savefig(config.TRAINING_PLOT_PATH)\n",
    "\n",
    "N = np.arange(0, len(clr.history[\"lr\"]))\n",
    "plt.figure()\n",
    "plt.plot(N, clr.history[\"lr\"])\n",
    "plt.title(\"Cyclical Learning Rate (CLR)\")\n",
    "plt.xlabel(\"Training Iterations\")\n",
    "plt.ylabel(\"Learning Rate\")\n",
    "plt.savefig(config.CLR_PLOT_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading images...\r\n"
     ]
    }
   ],
   "source": [
    "!python train.py --lr-find 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
